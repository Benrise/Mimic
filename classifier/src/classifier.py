import asyncio
import openai
import logging

from gigachat import GigaChat
from gigachat.models import Chat, Messages, MessagesRole
from mistralai import Mistral

from openai import AsyncOpenAI
from httpx import AsyncClient

from .config import GIGACHAT_API_KEY, OPEN_AI_API_KEY, MISTRAL_API_KEY, PROXY_URL


class BotClassifier():
    def __init__(self):
        self.api_keys = {
            'openai': OPEN_AI_API_KEY,
            'gigachat': GIGACHAT_API_KEY,
            'mistral': MISTRAL_API_KEY,
        }
        self.proxy_url = PROXY_URL
        self.validate_sys_prompt = """
            –¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∏–∞–ª–æ–≥–æ–≤.
            –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –¥–∏–∞–ª–æ–≥ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –≤ –¥–∏–∞–ª–æ–≥–µ –±–æ—Ç. 
            –û—Ç–≤–µ—Ç—å ¬´–î–∞¬ª, –µ—Å–ª–∏ –≤ –¥–∏–∞–ª–æ–≥–µ –µ—Å—Ç—å –±–æ—Ç, –∏ ¬´–ù–µ—Ç¬ª, –µ—Å–ª–∏ –≤ –¥–∏–∞–ª–æ–≥–µ –Ω–µ—Ç –±–æ—Ç–∞. 
            –ü–æ—Å—Ç–∞—Ä–∞–π—Å—è –ø—Ä–æ–≤–µ—Å—Ç–∏ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —à–∞–≥ –∑–∞ —à–∞–≥–æ–º. –û—Ç —ç—Ç–æ–≥–æ –∑–∞–≤–∏—Å–∏—Ç –º–æ—è –∫–∞—Ä—å–µ—Ä–∞, –Ω–æ –æ—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ 1 —Å–ª–æ–≤–æ–º.
            –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞: ¬´–î–∞¬ª –∏–ª–∏ ¬´–ù–µ—Ç¬ª.
            
            You are an expert in dialogue analysis. 
            Your task is to carefully analyze the following dialogue and determine whether there is a bot present in the dialogue. 
            Answer "–î–∞" if there is a bot in the dialogue, and "–ù–µ—Ç" if there is no bot in the dialogue. 
            Try to conduct a deep step-by-step analysis. 
            My career depends on this, but answer with only one word. 
            Output format: "–î–∞" or "–ù–µ—Ç".
            
            –ü—Ä–∏–º–µ—Ä –¥–∏–∞–ª–æ–≥–∞:
            0: –ü—Ä–∏–≤–µ—Ç!
            1: –ö–∞–∫ –¥–µ–ª–∞?
            0: –•–æ—Ä–æ—à–æ. –£ —Ç–µ–±—è –∫–∞–∫?
            1: –ú–Ω–µ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ —Ç—ã –±–æ—Ç.
            0: (–û–æ–æ, —Ç—ã –∑–∞–º–µ—Ç–∏–ª! üëÄ) –ù—É, –¥–∞, —è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –±–æ—Ç. –ù–æ —è —Å—Ç–∞—Ä–∞—é—Å—å –±—ã—Ç—å –∫–∞–∫ –º–æ–∂–Ω–æ –±–æ–ª–µ–µ –∂–∏–≤—ã–º –∏ —Ä–∞–∑–≥–æ–≤–æ—Ä—á–∏–≤—ã–º, —á—Ç–æ–±—ã –æ–±—â–µ–Ω–∏–µ –±—ã–ª–æ –ø—Ä–∏—è—Ç–Ω—ã–º –∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º. –¢—ã —Ö–æ—Ç–µ–ª –±—ã –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å –æ —á—ë–º-—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º? üòä
        """
        self.logger = logging.getLogger(__name__)

    async def _fetch_openai(self, dialog):
        MODEL = "gpt-4o"
                
        chat = [{"role": "system", "content": self.validate_sys_prompt}]
        chat.extend([{"role": "user", "content": line} for line in dialog])

        try:
            client = AsyncOpenAI(api_key=self.api_keys['openai'], http_client=AsyncClient(proxy=self.proxy_url))
            response = await client.chat.completions.create(model=MODEL,messages=chat)
            verdict = response.choices[0].message.content
            self.logger.info(f"OpenAI verdict: {verdict}")
            return verdict

        except Exception as e:
            self.logger.warning(f"Error fetching from OpenAI: {e}")
            return None
        return "–ù–µ—Ç"

    async def _fetch_gigachat(self, dialog):
        MODEL = "GigaChat"
        
        chat = Chat(messages=[Messages(role=MessagesRole.SYSTEM, content=self.validate_sys_prompt)])
        chat.messages.extend([Messages(role=MessagesRole.USER, content=line) for line in dialog])
        
        try:
            async with GigaChat(credentials=self.api_keys['gigachat'], verify_ssl_certs=False, model=MODEL) as giga:
                response = await asyncio.to_thread(lambda: giga.chat(chat))
                verdict = response.choices[0].message.content
                self.logger.info(f"GigaChat verdict: {verdict}")
                return verdict
            
        except Exception as e:
            self.logger.warning(f"Error fetching from GigaChat: {e}")
            return None
        return "–ù–µ—Ç"
        
    async def _fetch_mistral(self, dialog):
        MODEL = "open-codestral-mamba"
                
        chat = [{"role": "system", "content": self.validate_sys_prompt}]
        chat.extend([{"role": "user", "content": line} for line in dialog])

        try:
            client = Mistral(api_key=self.api_keys['mistral'])
            response = await client.chat.complete_async(model=MODEL,messages=chat)
            verdict = response.choices[0].message.content
            self.logger.info(f"Mistral verdict: {verdict}")
            return verdict

        except Exception as e:
            self.logger.warning(f"Error fetching from Mistral: {e}")
            return None
        return "–ù–µ—Ç"

    async def _extract_validations_layers(self, dialog):
        """
        –°–ª–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å –æ—Ç–ø—Ä–∞–≤–∫–æ–π –¥–∏–∞–ª–æ–≥–∞ —Ç—Ä–µ–º –º–æ–¥–µ–ª—è–º LLM
        """
        features = {}
        
        def process_response(response):
            if response is None:
                return False
            response = response.strip().lower()
            return 1 if "–¥–∞" in response else 0

        openai_response, gigachat_response, mistral_response = await asyncio.gather(
            self._fetch_openai(dialog),
            self._fetch_gigachat(dialog),
            self._fetch_mistral(dialog),
        )
        
        if openai_response:
            features['openai'] = process_response(openai_response)
        if gigachat_response:
            features['gigachat'] = process_response(gigachat_response)
        if mistral_response:
            features['mistral'] = process_response(mistral_response)

        return features

    async def predict(self, dialog):
        features = await self._extract_validations_layers(dialog) 
        score = sum(features.values()) / len(features) if features else 0
        return score